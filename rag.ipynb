{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d9f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ------------------------------------------------------------------\n",
    "# Using standard library facilities:\n",
    "# - os: interacting with the operating system for environment variables and file paths.\n",
    "import os\n",
    "\n",
    "# Using NumPy for efficient numerical arrays and vector operations required by embedding tensors.\n",
    "import numpy as np\n",
    "\n",
    "# Using the OpenAI SDK as the model-facing client for text generation and embeddings.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Using Chroma as the vector database for persistent storage and similarity search over embeddings.\n",
    "import chromadb\n",
    "\n",
    "# Using the EmbeddingFunction protocol to adapt an embedding provider to Chroma’s ingestion/query pipeline.\n",
    "from chromadb.api.types import EmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "054c76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration block ------------------------------------------------------\n",
    "# Using environment variables to externalize credentials, enabling reproducible\n",
    "# experimentation across local development, CI, and cloud deployments without hard-coded secrets.\n",
    "OPENAI_API = os.getenv(\"OPENAI_API\")\n",
    "assert OPENAI_API, \"Missing OPENAI_API\"\n",
    "\n",
    "# Using explicit model identifiers to keep ablations and benchmarking reproducible.\n",
    "# LLM_MODEL targets the conversational model for generation; EMB_MODEL targets the embedding model for vectorization.\n",
    "LLM_MODEL = \"gpt-4.1-nano\"           # primary conversational LLM\n",
    "EMB_MODEL = \"text-embedding-3-small\" # lightweight, cost-efficient embeddings\n",
    "\n",
    "# --- Generation parameters ----------------------------------------------------\n",
    "# Using explicit decoding hyperparameters to ensure determinism across runs.\n",
    "# TEMPERATURE controls stochasticity during decoding; MAX_TOKENS bounds generation length and cost.\n",
    "TEMPERATUER = 0.7\n",
    "MAX_TOKENS = 100\n",
    "\n",
    "# --- Clients ------------------------------------------------------------------\n",
    "# Using the native OpenAI client; authentication sourced from the environment variable declared above.\n",
    "llm_client = OpenAI(api_key=OPENAI_API)\n",
    "\n",
    "# Using Chroma Cloud as the vector store; authentication and multitenancy details supplied via environment variables.\n",
    "# Providing tenant and database explicitly to avoid ambiguous resolution on the backend.\n",
    "chroma = chromadb.CloudClient(\n",
    "    tenant=os.getenv(\"CHROMA_TENANT\"),\n",
    "    database=\"Test\",\n",
    "    api_key=os.getenv(\"CHROMADB_TOKEN\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22098e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Embedding wrapper --------------------------------------------------------\n",
    "# Defining an adapter class to integrate OpenAI’s embedding API with Chroma ingestion.\n",
    "# The class conforms to Chroma’s EmbeddingFunction protocol, enabling drop-in substitution of\n",
    "# embedding providers while preserving a stable interface for downstream vectorization.\n",
    "class OpenAIEmbeddingFunction(EmbeddingFunction[str]):\n",
    "    def __init__(self, client: OpenAI, model: str):\n",
    "        # Storing the OpenAI client instance, responsible for routing requests to the embedding endpoint.\n",
    "        # Storing the specific model identifier that determines the embedding representation.\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Normalizing the input to a list structure, ensuring batch consistency for both single and multi-string inputs.\n",
    "        if isinstance(inputs, str):\n",
    "            inputs = [inputs]\n",
    "        # Requesting embeddings from the OpenAI API for the normalized input batch.\n",
    "        resp = self.client.embeddings.create(model=self.model, input=inputs)\n",
    "        # Casting returned embeddings into NumPy arrays for numerical stability and compatibility\n",
    "        # with Chroma’s storage and similarity search operations.\n",
    "        return [np.array(item.embedding, dtype=np.float32) for item in resp.data]\n",
    "\n",
    "# Instantiating the embedding function, making it available for explicit precomputation of vectors.\n",
    "emb_fn = OpenAIEmbeddingFunction(llm_client, EMB_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd654dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM interaction ----------------------------------------------------------\n",
    "# Using a minimal chat completion request to validate connectivity and authentication.\n",
    "# The interaction specifies:\n",
    "# - model: the target conversational model.\n",
    "# - temperature: the stochasticity of the decoding process.\n",
    "# - max_tokens: the cap on generated tokens to control cost and verbosity.\n",
    "# - messages: a structured dialogue context containing both system and user roles.\n",
    "chat = llm_client.chat.completions.create(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=TEMPERATUER,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente útil y conciso.\"},\n",
    "        {\"role\": \"user\", \"content\": \"¿Cuál es la capital de Francia?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92fbe926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capital de Francia es París.\n"
     ]
    }
   ],
   "source": [
    "# --- Validation cell: LLM connectivity test -----------------------------------\n",
    "# Using a direct print of the assistant's reply to confirm that the model responds as expected.\n",
    "print(chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ab54db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colección lista: document_qa_collection\n"
     ]
    }
   ],
   "source": [
    "# --- Creating or retrieving a Chroma collection -------------------------------\n",
    "# Defining a symbolic name for the collection, binding stored documents and their embeddings\n",
    "# under a reproducible identifier that can be referenced across experiments.\n",
    "collection_name = \"document_qa_collection\"\n",
    "\n",
    "# Creating (or retrieving) the collection from Chroma. Since embeddings are precomputed\n",
    "# explicitly, no embedding_function is attached at collection instantiation.\n",
    "collection = chroma.get_or_create_collection(\n",
    "    name=collection_name,\n",
    ")\n",
    "\n",
    "# Printing the collection name to confirm that the resource is available and accessible.\n",
    "print(\"Colección lista:\", collection.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a386ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to load documents from a directory ------------------------------\n",
    "def load_documents_from_directory(directory_path):\n",
    "    # Printing a marker to indicate the start of the loading process for traceability.\n",
    "    print(\"==== Loading documents from directory ====\")\n",
    "\n",
    "    # Initializing a list to accumulate document records.\n",
    "    documents = []\n",
    "\n",
    "    # Iterating over all files in the specified directory.\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Filtering for files with a .txt extension to ensure textual input only.\n",
    "        if filename.endswith(\".txt\"):\n",
    "            # Opening each file with UTF-8 encoding to handle multilingual characters consistently.\n",
    "            with open(os.path.join(directory_path, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                # Appending a dictionary containing the filename (as a stable identifier)\n",
    "                # and the raw file content.\n",
    "                documents.append({\"id\": filename, \"text\": file.read()})\n",
    "\n",
    "    # Returning the list of loaded document records for downstream processing.\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b4b0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Loading documents from directory ====\n",
      "number of documents: 21\n",
      "Signaling that investments in the supply chain sec\n"
     ]
    }
   ],
   "source": [
    "# --- Loading and inspecting documents -----------------------------------------\n",
    "# Reloading documents from the specified directory.\n",
    "documents = load_documents_from_directory(\"news_articles\")\n",
    "\n",
    "# Printing the total number of documents as a coarse diagnostic of corpus size.\n",
    "print(f\"number of documents: {len(documents)}\")\n",
    "\n",
    "# Printing the first 50 characters of the first document to validate content ingestion.\n",
    "print(documents[0]['text'][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b86f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to split text into chunks ---------------------------------------\n",
    "def split_text(text, chunk_size=1000, chunk_overlap=30):\n",
    "    # Initializing an accumulator list to hold the resulting text segments.\n",
    "    chunks = []\n",
    "    # Starting index for segmentation.\n",
    "    start = 0\n",
    "    # Iterating until the end of the input text is reached.\n",
    "    while start < len(text):\n",
    "        # Computing the endpoint for the current segment.\n",
    "        end = start + chunk_size\n",
    "        # Appending the substring defined by [start:end] to the accumulator.\n",
    "        chunks.append(text[start:end])\n",
    "        # Advancing the starting index by chunk_size while retaining\n",
    "        # an overlap of 'chunk_overlap' characters to preserve local context.\n",
    "        start = end - chunk_overlap\n",
    "    # Returning the list of overlapping text segments.\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e78aac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Splitting all documents into chunks --------------------------------------\n",
    "# Iterating over the loaded documents and segmenting each into overlapping chunks\n",
    "# for downstream embedding and retrieval.\n",
    "chunked_documents = []\n",
    "\n",
    "for doc in documents:\n",
    "    # Splitting the current document’s text into fixed-size overlapping segments.\n",
    "    chunks = split_text(doc[\"text\"])\n",
    "    # Enumerating over the resulting segments to assign stable identifiers.\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Constructing a record with:\n",
    "        # - id: composed of the document filename and chunk index\n",
    "        # - text: the raw chunk content\n",
    "        chunked_documents.append({\n",
    "            \"id\": f\"{doc['id']}_chunk{i+1}\",\n",
    "            \"text\": chunk\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9632d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 185\n",
      "\n",
      "--- First chunk metadata ---\n",
      "{'id': '05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt_chunk1', 'text': 'Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”\\n\\nPando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based frei'}\n",
      "\n",
      "--- First chunk text preview ---\n",
      "Signaling that investments in \n"
     ]
    }
   ],
   "source": [
    "# --- Inspecting chunked documents ---------------------------------------------\n",
    "# Measuring the total number of generated chunks across all documents.\n",
    "print(f\"Total number of chunks: {len(chunked_documents)}\")\n",
    "\n",
    "# Printing the metadata of the first chunk to validate structure (id + text fields).\n",
    "print(\"\\n--- First chunk metadata ---\")\n",
    "print(chunked_documents[0])\n",
    "\n",
    "# Printing a readable preview of the text content of the first chunk.\n",
    "print(\"\\n--- First chunk text preview ---\")\n",
    "print(chunked_documents[0]['text'][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c55e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Precomputing embeddings ---------------------------------------------------\n",
    "# Defining a utility function for explicit embedding computation.\n",
    "# The function requests a vector representation for a given text and returns\n",
    "# the first (and only) embedding from the response as a NumPy array.\n",
    "def get_openai_embedding(text):\n",
    "    return emb_fn(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f497a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Embedding test ---\n",
      "Input text: hello world\n",
      "Vector shape: (1536,)\n",
      "First 10 dimensions: [-0.00676333 -0.03919632  0.03417581  0.02876212 -0.02478502 -0.04203926\n",
      " -0.03028944  0.04932809 -0.01389715 -0.01764742]\n"
     ]
    }
   ],
   "source": [
    "# --- Test: embedding a sample string ------------------------------------------\n",
    "# Using a simple \"hello world\" string to validate that the embedding function\n",
    "# returns a numerical vector of the expected dimensionality.\n",
    "test_text = \"hello world\"\n",
    "embedding = get_openai_embedding(test_text)\n",
    "\n",
    "print(\"--- Embedding test ---\")\n",
    "print(f\"Input text: {test_text}\")\n",
    "print(f\"Vector shape: {embedding.shape}\")\n",
    "print(f\"First 10 dimensions: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0375ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Embedding chunk 1 ------------\n",
      "------------ Embedding chunk 2 ------------\n",
      "------------ Embedding chunk 3 ------------\n",
      "------------ Embedding chunk 4 ------------\n",
      "------------ Embedding chunk 5 ------------\n",
      "------------ Embedding chunk 6 ------------\n",
      "------------ Embedding chunk 7 ------------\n",
      "------------ Embedding chunk 8 ------------\n",
      "------------ Embedding chunk 9 ------------\n",
      "------------ Embedding chunk 10 ------------\n",
      "------------ Embedding chunk 11 ------------\n",
      "------------ Embedding chunk 12 ------------\n",
      "------------ Embedding chunk 13 ------------\n",
      "------------ Embedding chunk 14 ------------\n",
      "------------ Embedding chunk 15 ------------\n",
      "------------ Embedding chunk 16 ------------\n",
      "------------ Embedding chunk 17 ------------\n",
      "------------ Embedding chunk 18 ------------\n",
      "------------ Embedding chunk 19 ------------\n",
      "------------ Embedding chunk 20 ------------\n",
      "------------ Embedding chunk 21 ------------\n",
      "------------ Embedding chunk 22 ------------\n",
      "------------ Embedding chunk 23 ------------\n",
      "------------ Embedding chunk 24 ------------\n",
      "------------ Embedding chunk 25 ------------\n",
      "------------ Embedding chunk 26 ------------\n",
      "------------ Embedding chunk 27 ------------\n",
      "------------ Embedding chunk 28 ------------\n",
      "------------ Embedding chunk 29 ------------\n",
      "------------ Embedding chunk 30 ------------\n",
      "------------ Embedding chunk 31 ------------\n",
      "------------ Embedding chunk 32 ------------\n",
      "------------ Embedding chunk 33 ------------\n",
      "------------ Embedding chunk 34 ------------\n",
      "------------ Embedding chunk 35 ------------\n",
      "------------ Embedding chunk 36 ------------\n",
      "------------ Embedding chunk 37 ------------\n",
      "------------ Embedding chunk 38 ------------\n",
      "------------ Embedding chunk 39 ------------\n",
      "------------ Embedding chunk 40 ------------\n",
      "------------ Embedding chunk 41 ------------\n",
      "------------ Embedding chunk 42 ------------\n",
      "------------ Embedding chunk 43 ------------\n",
      "------------ Embedding chunk 44 ------------\n",
      "------------ Embedding chunk 45 ------------\n",
      "------------ Embedding chunk 46 ------------\n",
      "------------ Embedding chunk 47 ------------\n",
      "------------ Embedding chunk 48 ------------\n",
      "------------ Embedding chunk 49 ------------\n",
      "------------ Embedding chunk 50 ------------\n",
      "------------ Embedding chunk 51 ------------\n",
      "------------ Embedding chunk 52 ------------\n",
      "------------ Embedding chunk 53 ------------\n",
      "------------ Embedding chunk 54 ------------\n",
      "------------ Embedding chunk 55 ------------\n",
      "------------ Embedding chunk 56 ------------\n",
      "------------ Embedding chunk 57 ------------\n",
      "------------ Embedding chunk 58 ------------\n",
      "------------ Embedding chunk 59 ------------\n",
      "------------ Embedding chunk 60 ------------\n",
      "------------ Embedding chunk 61 ------------\n",
      "------------ Embedding chunk 62 ------------\n",
      "------------ Embedding chunk 63 ------------\n",
      "------------ Embedding chunk 64 ------------\n",
      "------------ Embedding chunk 65 ------------\n",
      "------------ Embedding chunk 66 ------------\n",
      "------------ Embedding chunk 67 ------------\n",
      "------------ Embedding chunk 68 ------------\n",
      "------------ Embedding chunk 69 ------------\n",
      "------------ Embedding chunk 70 ------------\n",
      "------------ Embedding chunk 71 ------------\n",
      "------------ Embedding chunk 72 ------------\n",
      "------------ Embedding chunk 73 ------------\n",
      "------------ Embedding chunk 74 ------------\n",
      "------------ Embedding chunk 75 ------------\n",
      "------------ Embedding chunk 76 ------------\n",
      "------------ Embedding chunk 77 ------------\n",
      "------------ Embedding chunk 78 ------------\n",
      "------------ Embedding chunk 79 ------------\n",
      "------------ Embedding chunk 80 ------------\n",
      "------------ Embedding chunk 81 ------------\n",
      "------------ Embedding chunk 82 ------------\n",
      "------------ Embedding chunk 83 ------------\n",
      "------------ Embedding chunk 84 ------------\n",
      "------------ Embedding chunk 85 ------------\n",
      "------------ Embedding chunk 86 ------------\n",
      "------------ Embedding chunk 87 ------------\n",
      "------------ Embedding chunk 88 ------------\n",
      "------------ Embedding chunk 89 ------------\n",
      "------------ Embedding chunk 90 ------------\n",
      "------------ Embedding chunk 91 ------------\n",
      "------------ Embedding chunk 92 ------------\n",
      "------------ Embedding chunk 93 ------------\n",
      "------------ Embedding chunk 94 ------------\n",
      "------------ Embedding chunk 95 ------------\n",
      "------------ Embedding chunk 96 ------------\n",
      "------------ Embedding chunk 97 ------------\n",
      "------------ Embedding chunk 98 ------------\n",
      "------------ Embedding chunk 99 ------------\n",
      "------------ Embedding chunk 100 ------------\n",
      "------------ Embedding chunk 101 ------------\n",
      "------------ Embedding chunk 102 ------------\n",
      "------------ Embedding chunk 103 ------------\n",
      "------------ Embedding chunk 104 ------------\n",
      "------------ Embedding chunk 105 ------------\n",
      "------------ Embedding chunk 106 ------------\n",
      "------------ Embedding chunk 107 ------------\n",
      "------------ Embedding chunk 108 ------------\n",
      "------------ Embedding chunk 109 ------------\n",
      "------------ Embedding chunk 110 ------------\n",
      "------------ Embedding chunk 111 ------------\n",
      "------------ Embedding chunk 112 ------------\n",
      "------------ Embedding chunk 113 ------------\n",
      "------------ Embedding chunk 114 ------------\n",
      "------------ Embedding chunk 115 ------------\n",
      "------------ Embedding chunk 116 ------------\n",
      "------------ Embedding chunk 117 ------------\n",
      "------------ Embedding chunk 118 ------------\n",
      "------------ Embedding chunk 119 ------------\n",
      "------------ Embedding chunk 120 ------------\n",
      "------------ Embedding chunk 121 ------------\n",
      "------------ Embedding chunk 122 ------------\n",
      "------------ Embedding chunk 123 ------------\n",
      "------------ Embedding chunk 124 ------------\n",
      "------------ Embedding chunk 125 ------------\n",
      "------------ Embedding chunk 126 ------------\n",
      "------------ Embedding chunk 127 ------------\n",
      "------------ Embedding chunk 128 ------------\n",
      "------------ Embedding chunk 129 ------------\n",
      "------------ Embedding chunk 130 ------------\n",
      "------------ Embedding chunk 131 ------------\n",
      "------------ Embedding chunk 132 ------------\n",
      "------------ Embedding chunk 133 ------------\n",
      "------------ Embedding chunk 134 ------------\n",
      "------------ Embedding chunk 135 ------------\n",
      "------------ Embedding chunk 136 ------------\n",
      "------------ Embedding chunk 137 ------------\n",
      "------------ Embedding chunk 138 ------------\n",
      "------------ Embedding chunk 139 ------------\n",
      "------------ Embedding chunk 140 ------------\n",
      "------------ Embedding chunk 141 ------------\n",
      "------------ Embedding chunk 142 ------------\n",
      "------------ Embedding chunk 143 ------------\n",
      "------------ Embedding chunk 144 ------------\n",
      "------------ Embedding chunk 145 ------------\n",
      "------------ Embedding chunk 146 ------------\n",
      "------------ Embedding chunk 147 ------------\n",
      "------------ Embedding chunk 148 ------------\n",
      "------------ Embedding chunk 149 ------------\n",
      "------------ Embedding chunk 150 ------------\n",
      "------------ Embedding chunk 151 ------------\n",
      "------------ Embedding chunk 152 ------------\n",
      "------------ Embedding chunk 153 ------------\n",
      "------------ Embedding chunk 154 ------------\n",
      "------------ Embedding chunk 155 ------------\n",
      "------------ Embedding chunk 156 ------------\n",
      "------------ Embedding chunk 157 ------------\n",
      "------------ Embedding chunk 158 ------------\n",
      "------------ Embedding chunk 159 ------------\n",
      "------------ Embedding chunk 160 ------------\n",
      "------------ Embedding chunk 161 ------------\n",
      "------------ Embedding chunk 162 ------------\n",
      "------------ Embedding chunk 163 ------------\n",
      "------------ Embedding chunk 164 ------------\n",
      "------------ Embedding chunk 165 ------------\n",
      "------------ Embedding chunk 166 ------------\n",
      "------------ Embedding chunk 167 ------------\n",
      "------------ Embedding chunk 168 ------------\n",
      "------------ Embedding chunk 169 ------------\n",
      "------------ Embedding chunk 170 ------------\n",
      "------------ Embedding chunk 171 ------------\n",
      "------------ Embedding chunk 172 ------------\n",
      "------------ Embedding chunk 173 ------------\n",
      "------------ Embedding chunk 174 ------------\n",
      "------------ Embedding chunk 175 ------------\n",
      "------------ Embedding chunk 176 ------------\n",
      "------------ Embedding chunk 177 ------------\n",
      "------------ Embedding chunk 178 ------------\n",
      "------------ Embedding chunk 179 ------------\n",
      "------------ Embedding chunk 180 ------------\n",
      "------------ Embedding chunk 181 ------------\n",
      "------------ Embedding chunk 182 ------------\n",
      "------------ Embedding chunk 183 ------------\n",
      "------------ Embedding chunk 184 ------------\n",
      "------------ Embedding chunk 185 ------------\n"
     ]
    }
   ],
   "source": [
    "# --- Embedding all chunks -----------------------------------------------------\n",
    "# Iterating through the segmented documents and precomputing embeddings for each.\n",
    "# For traceability, printing progress messages with a running index.\n",
    "i = 1\n",
    "for doc in chunked_documents:\n",
    "    print(f\"------------ Embedding chunk {i} ------------\")\n",
    "    doc[\"embedding\"] = get_openai_embedding(doc[\"text\"])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0bac2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt_chunk1', 'text': 'Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”\\n\\nPando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based frei', 'embedding': array([-0.00112036,  0.03297736,  0.02428085, ..., -0.02802209,\n",
      "        0.02656028, -0.02295532], dtype=float32)}\n",
      "---------- embedding shape ----------\n",
      "(1536,)\n"
     ]
    }
   ],
   "source": [
    "# --- Inspecting the first chunk record ----------------------------------------\n",
    "# Printing the full structure of the first chunk after embedding has been attached.\n",
    "# The dictionary now contains:\n",
    "# - \"id\": unique identifier (filename + chunk index)\n",
    "# - \"text\": raw chunk content\n",
    "# - \"embedding\": precomputed numerical vector representation\n",
    "print(chunked_documents[0])\n",
    "print(\"---------- embedding shape ----------\")\n",
    "print(chunked_documents[0][\"embedding\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "383257ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ingesting precomputed embeddings into Chroma -----------------------------\n",
    "# Adding the chunked documents into the target collection. Each entry is defined by:\n",
    "# - ids: unique identifiers for individual chunks\n",
    "# - documents: raw text content for reference and retrieval\n",
    "# - embeddings: precomputed numerical vectors aligned with each chunk\n",
    "collection.add(\n",
    "    ids=[doc[\"id\"] for doc in chunked_documents],\n",
    "    documents=[doc[\"text\"] for doc in chunked_documents],\n",
    "    embeddings=[doc[\"embedding\"] for doc in chunked_documents]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c9940ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully stored in local Chroma instance at './chroma_db'\n"
     ]
    }
   ],
   "source": [
    "# --- Local persistence with Chroma --------------------------------------------\n",
    "# Initializing a persistent client that stores all data on disk in the folder \"./chroma_db\".\n",
    "# This enables offline access and reproducibility without depending on the cloud service.\n",
    "chroma_local = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# Creating (or retrieving) a local collection with the same identifier as the cloud counterpart.\n",
    "collection_local = chroma_local.get_or_create_collection(\n",
    "    name=\"document_qa_collection\"\n",
    ")\n",
    "\n",
    "# Ingesting the precomputed embeddings into the local collection.\n",
    "# Each entry is defined by:\n",
    "# - ids: stable identifiers for each chunk\n",
    "# - documents: raw text for reference\n",
    "# - embeddings: explicit numerical vectors\n",
    "collection_local.add(\n",
    "    ids=[doc[\"id\"] for doc in chunked_documents],\n",
    "    documents=[doc[\"text\"] for doc in chunked_documents],\n",
    "    embeddings=[doc[\"embedding\"] for doc in chunked_documents]\n",
    ")\n",
    "\n",
    "print(\"Data successfully stored in local Chroma instance at './chroma_db'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d7b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
